# -*- coding: utf-8 -*-
import re
import time
import traceback
from io import BytesIO
from pathlib import Path
from datetime import datetime
from urllib.parse import urlsplit, urlunsplit

from playwright.sync_api import sync_playwright
from docx import Document
from docx.shared import Inches
from docx.image.exceptions import UnrecognizedImageError

# å¯é¸ï¼šwebp -> pngï¼ˆæ²’è£ PIL ä¹Ÿèƒ½è·‘ï¼Œåªæ˜¯ webp å¯èƒ½æ’ä¸é€² docxï¼‰
try:
    from PIL import Image
    PIL_OK = True
except Exception:
    PIL_OK = False


# =====================
# ä½ è¦çš„å›ºå®šè¨­å®š
# =====================
OUT_DIR = Path(r"F:\F\AI\FB")                 # âœ… DOCX å›ºå®šè¼¸å‡ºåˆ°é€™è£¡
USER_DATA_DIR = r"F:\F\AI\pw_profile_fb"      # âœ… FB ç™»å…¥æŒä¹…åŒ–è³‡æ–™å¤¾ï¼ˆç¬¬ä¸€æ¬¡ç™»å…¥å¾Œæœƒè¨˜ä½ï¼‰
SLEEP_SEC = 0.25
MAX_IMAGES = 40


# =====================
# å·¥å…·
# =====================
def normalize_url(url: str) -> str:
    url = (url or "").strip()
    if not url:
        return ""
    if not url.startswith("http"):
        url = "https://" + url
    sp = urlsplit(url)
    return urlunsplit((sp.scheme, sp.netloc, sp.path, sp.query, ""))  # å»æ‰ #fragment


def safe_filename(s: str, max_len=120) -> str:
    s = re.sub(r'[<>:"/\\|?*]', "_", (s or "").strip())
    s = re.sub(r"\s+", "_", s)     # âœ… ç©ºç™½ -> _
    s = re.sub(r"_+", "_", s)
    s = s.strip("_")
    if len(s) > max_len:
        s = s[:max_len].rstrip("_")
    return s or "Facebook"


def choose_available_path(folder: Path, base_name: str) -> Path:
    p0 = folder / f"{base_name}.docx"
    if not p0.exists():
        return p0
    for i in range(1, 200):
        p = folder / f"{base_name}_{i:02d}.docx"
        if not p.exists():
            return p
    return folder / f"{base_name}_{int(time.time())}.docx"


def date8_from_iso(dt_str: str) -> str:
    if not dt_str:
        return ""
    m = re.search(r"(20\d{2})-(\d{1,2})-(\d{1,2})", dt_str)
    if not m:
        return ""
    y, mo, d = m.group(1), int(m.group(2)), int(m.group(3))
    return f"{y}{mo:02d}{d:02d}"


def clean_text(raw: str) -> str:
    raw = raw or ""
    lines = []
    for ln in raw.splitlines():
        ln = ln.strip()
        if not ln:
            continue
        # å¸¸è¦‹ UI å™ªéŸ³ï¼ˆçŸ­å­—ï¼‰
        bad_short = {"è®š", "ç•™è¨€", "åˆ†äº«", "æœ€ç›¸é—œ", "æ›´å¤š", "æŸ¥çœ‹æ›´å¤š", "æŸ¥çœ‹ç¿»è­¯", "å›è¦†", "å·²ç·¨è¼¯"}
        if ln in bad_short:
            continue
        lines.append(ln)

    # å»é‡
    out = []
    seen = set()
    for ln in lines:
        if ln in seen:
            continue
        seen.add(ln)
        out.append(ln)
    return "\n".join(out).strip()


# =====================
# é¸æœ€ä½³å®¹å™¨ï¼šdialog > article > main
# =====================
def get_best_container(page):
    dialogs = page.locator('div[role="dialog"]')
    best = None
    best_score = -1

    for i in range(dialogs.count()):
        d = dialogs.nth(i)
        aria = (d.get_attribute("aria-label") or "").lower()
        if "messenger" in aria or "chat" in aria:
            continue

        score = 0
        try:
            if d.locator('div[data-ad-preview="message"]').count() > 0:
                score += 8
        except Exception:
            pass
        try:
            if d.locator("time[datetime]").count() > 0:
                score += 7
        except Exception:
            pass
        try:
            score += min(d.locator('div[dir="auto"]').count(), 10)
        except Exception:
            pass

        if score > best_score:
            best_score = score
            best = d

    if best is not None and best_score >= 7:
        return best

    art = page.locator('div[role="article"]').first
    if art.count():
        return art

    main = page.locator('div[role="main"]').first
    if main.count():
        return main

    return page.locator("body").first


# =====================
# æŠ“ POæ–‡æ—¥æœŸï¼ˆæœ€é‡è¦ï¼‰
# =====================
def extract_post_datetime(container, page) -> str:
    """
    âœ… ä½ è¦çš„ PO æ–‡æ—¥æœŸä¾†æºï¼š
    å„ªå…ˆæŠ“è²¼æ–‡å€å¡Šå…§çš„ time[datetime]ï¼ˆæœ€æº–ï¼‰
    """
    # 1) container å…§ time[datetime]
    try:
        t = container.locator("time[datetime]").first
        if t.count():
            dt = (t.get_attribute("datetime") or "").strip()
            if dt:
                return dt
    except Exception:
        pass

    # 2) å…¨é  time[datetime]ï¼ˆé€€è·¯ï¼‰
    try:
        t = page.locator("time[datetime]").first
        if t.count():
            dt = (t.get_attribute("datetime") or "").strip()
            if dt:
                return dt
    except Exception:
        pass

    return ""


def extract_title(page) -> str:
    try:
        t = page.locator('meta[property="og:title"]').get_attribute("content")
        if t:
            return t.strip()
    except Exception:
        pass
    try:
        t = page.title()
        if t:
            return t.strip()
    except Exception:
        pass
    return "Facebook"


def extract_text(container) -> str:
    # 1) data-ad-preview="message"
    try:
        m = container.locator('div[data-ad-preview="message"]').first
        if m.count():
            return clean_text(m.inner_text(timeout=8000))
    except Exception:
        pass

    # 2) dir=auto
    try:
        d = container.locator('div[dir="auto"]').first
        if d.count():
            return clean_text(d.inner_text(timeout=8000))
    except Exception:
        pass

    # 3) container å…¨éƒ¨æ–‡å­—
    try:
        return clean_text(container.inner_text(timeout=8000))
    except Exception:
        return ""


def collect_images_bytes(context_request, container):
    imgs_bytes = []
    seen = set()

    loc = container.locator('img[data-visualcompletion="media-vc-image"]')
    if loc.count() == 0:
        loc = container.locator("img")

    for i in range(min(loc.count(), MAX_IMAGES)):
        im = loc.nth(i)
        try:
            src = (im.get_attribute("src") or "").strip()
            if not src or src in seen:
                continue
            seen.add(src)

            # éæ¿¾éå¸¸å°çš„ icon/é ­åƒï¼ˆå¯¬é«˜å–ä¸åˆ°å°±ä¸æ“‹ï¼‰
            w = im.get_attribute("width")
            h = im.get_attribute("height")
            try:
                wi = int(w) if (w and str(w).isdigit()) else 999
                hi = int(h) if (h and str(h).isdigit()) else 999
                if wi < 80 or hi < 80:
                    continue
            except Exception:
                pass

            r = context_request.get(src, timeout=25000)
            if not r.ok:
                continue
            b = r.body()
            if b:
                imgs_bytes.append(b)
        except Exception:
            continue

    return imgs_bytes


def add_image_to_doc(doc: Document, b: bytes) -> bool:
    if not b:
        return False

    # å…ˆå˜—è©¦ç”¨ PIL è½‰ PNG
    if PIL_OK:
        try:
            im = Image.open(BytesIO(b))
            out = BytesIO()
            im.convert("RGB").save(out, format="PNG")
            out.seek(0)
            doc.add_picture(out, width=Inches(6.3))
            return True
        except Exception:
            pass

    try:
        doc.add_picture(BytesIO(b), width=Inches(6.3))
        return True
    except UnrecognizedImageError:
        return False
    except Exception:
        return False


# =====================
# MAIN
# =====================
def main():
    url = normalize_url(input("è«‹è¼¸å…¥ FB è²¼æ–‡ç¶²å€ï¼š\n").strip())
    if not url:
        print("âŒ æœªè¼¸å…¥ç¶²å€ï¼ŒçµæŸ")
        return

    OUT_DIR.mkdir(parents=True, exist_ok=True)

    with sync_playwright() as p:
        # âœ… é‡é»ï¼šæŒä¹…åŒ– contextï¼ˆä¿ç•™ç™»å…¥ï¼‰
        context = p.chromium.launch_persistent_context(
            user_data_dir=USER_DATA_DIR,
            headless=False,       # FB å»ºè­°æœ‰é ­æ¨¡å¼
            locale="zh-TW",
            viewport={"width": 1366, "height": 900},
        )
        page = context.new_page()

        page.goto(url, wait_until="domcontentloaded", timeout=60000)
        page.wait_for_timeout(3000)

        container = get_best_container(page)

        title = extract_title(page)

        post_dt_iso = extract_post_datetime(container, page)
        post_date8 = date8_from_iso(post_dt_iso)

        # âœ… æŠ“ä¸åˆ°å°±è­¦å‘Šï¼ˆä¸å†é»˜é»˜ç”¨ä»Šå¤©ï¼‰
        if not post_date8:
            print("âš ï¸ è­¦å‘Šï¼šæœªæŠ“åˆ° POæ–‡æ—¥æœŸï¼ˆtime[datetime]ï¼‰ï¼Œå¯èƒ½å°šæœªç™»å…¥æˆ–è²¼æ–‡æœªå®Œæ•´è¼‰å…¥ã€‚")
            post_date8 = datetime.now().strftime("%Y%m%d")

        content = extract_text(container)
        images = collect_images_bytes(context.request, container)

        # âœ… é—œé–‰æŒä¹…åŒ– contextï¼ˆä½†ç™»å…¥æœƒä¿ç•™åœ¨ USER_DATA_DIRï¼‰
        context.close()

    # âœ… æª”åï¼šPOæ–‡æ—¥æœŸ + æ¨™é¡Œ
    base = safe_filename(title)
    out_path = choose_available_path(OUT_DIR, f"{post_date8}_{base}")

    doc = Document()
    doc.add_heading(title, level=0)
    doc.add_paragraph(f"ä¾†æºç¶²å€ï¼š{url}")
    doc.add_paragraph(f"POæ–‡æ—¥æœŸï¼š{post_date8}")
    if post_dt_iso:
        doc.add_paragraph(f"POæ–‡æ™‚é–“(datetime)ï¼š{post_dt_iso}")
    doc.add_paragraph("")

    if content:
        for line in content.splitlines():
            doc.add_paragraph(line)
    else:
        doc.add_paragraph("ï¼ˆæœªæˆåŠŸæŠ½å–åˆ°æ­£æ–‡ï¼Œå¯èƒ½éœ€è¦ç™»å…¥æˆ–è²¼æ–‡æ¬Šé™å—é™ï¼‰")

    img_ok = 0
    if images:
        doc.add_paragraph("")
        doc.add_paragraph("ã€åœ–ç‰‡ã€‘")
        for b in images[:30]:
            if add_image_to_doc(doc, b):
                img_ok += 1
                time.sleep(SLEEP_SEC)

    doc.save(out_path)

    print(f"âœ… å®Œæˆï¼š{out_path}")
    print(f"ğŸ“Œ åœ–ç‰‡ï¼š{img_ok} å¼µ")
    print(f"ğŸ“… POæ–‡æ—¥æœŸ(YYYYMMDD)ï¼š{post_date8}")


if __name__ == "__main__":
    try:
        main()
    except Exception:
        print("âŒ ç¨‹å¼ç™¼ç”Ÿæœªè™•ç†ä¾‹å¤–ï¼š")
        traceback.print_exc()
        # âœ… ä¸æš«åœï¼Œç›´æ¥å› CMD
